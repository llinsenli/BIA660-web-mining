{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Q1 function\n",
    "def tokenize(text):\n",
    "    \n",
    "    tokens = None\n",
    "    text_lower = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    pattern = r'[a-zA-Z]+[-\\._\\']*[a-zA-Z]+'\n",
    "    token1 = nltk.regexp_tokenize(text_lower,pattern)\n",
    "    tokens = [i for i in token1 if i not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Q3 function\n",
    "\n",
    "def find_similar_doc(docs,  doc_id):\n",
    "    top_sim_index, top_sim_score = None, None\n",
    "    # Use the Q1 function to tokenize each doc in docs\n",
    "    tokens = [tokenize(i) for i in docs]\n",
    "    dic = [nltk.FreqDist(token) for token in tokens]\n",
    "    docs_tokens={idx:doc for idx,doc in enumerate(dic)}\n",
    "    \n",
    "    # Get document-term matrix\n",
    "    dtm = pd.DataFrame.from_dict(docs_tokens, orient=\"index\" )\n",
    "    dtm = dtm.fillna(0)\n",
    "    dtm = dtm.sort_index(axis = 0) \n",
    "    \n",
    "    # Get normalized term frequency (tf) matrix\n",
    "    tf = dtm.values\n",
    "    doc_len = tf.sum(axis = 1)\n",
    "    tf = np.divide(tf, doc_len[:,None])\n",
    "    \n",
    "    # Get idf\n",
    "    df = np.where(tf > 0,1,0)\n",
    "    idf = np.log(np.divide(len(docs), np.sum(df, axis = 0))) + 1\n",
    "    smoothed_idf = np.log(np.divide(len(docs) + 1, np.sum(df, axis = 0) + 1)) + 1\n",
    "    \n",
    "    # Get tf-idf\n",
    "    tf_idf = normalize(tf * idf)\n",
    "    smoothed_tf_idf = normalize(tf * smoothed_idf)\n",
    "\n",
    "    # Use the smoothed_tf_idf to compare the distence between target and others\n",
    "    target = smoothed_tf_idf[doc_id,:] \n",
    "    score = [1 - distance.cosine(target, smoothed_tf_idf[i,:]) for i in range(len(docs))]\n",
    "    dtm['score'] = score \n",
    "    dtm_sort = dtm.sort_values(by=['score'],ascending=False)\n",
    "    top_sim_index = dtm_sort.index.values[1]\n",
    "    top_sim_score = dtm_sort['score'].values[1]\n",
    "    \n",
    "    \n",
    "    return top_sim_index, top_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab\n",
    "data = pd.read_csv(\"amazon_review_300.csv\")\n",
    "docs = data[\"review\"]\n",
    "# Use the Q1 function to tokenize each doc in docs\n",
    "tokens = [tokenize(i) for i in docs]\n",
    "dic = [nltk.FreqDist(token) for token in tokens]\n",
    "docs_tokens={idx:doc for idx,doc in enumerate(dic)}\n",
    "# Get document-term matrix\n",
    "dtm = pd.DataFrame.from_dict(docs_tokens, orient=\"index\" )\n",
    "dtm = dtm.fillna(0)\n",
    "dtm = dtm.sort_index(axis = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_arr = np.array([find_similar_doc(docs,i) for i in range(300)])\n",
    "col1 = result_arr[:,0]\n",
    "col2 = result_arr[:,1]\n",
    "dtm['top_sim_index'] = col1\n",
    "dtm['top_sim_score'] = col2\n",
    "result = dtm.iloc[:,[-2,-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_sim_index</th>\n",
       "      <th>top_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>153.280000</td>\n",
       "      <td>0.191250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>91.399752</td>\n",
       "      <td>0.104174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.125883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.166524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>232.500000</td>\n",
       "      <td>0.223430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>0.911463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       top_sim_index  top_sim_score\n",
       "count     300.000000     300.000000\n",
       "mean      153.280000       0.191250\n",
       "std        91.399752       0.104174\n",
       "min         1.000000       0.055308\n",
       "25%        69.000000       0.125883\n",
       "50%       156.000000       0.166524\n",
       "75%       232.500000       0.223430\n",
       "max       299.000000       0.911463"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1168b6cc0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.hist('top_sim_score',bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = result.sort_values(by=['top_sim_score'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_sim_index</th>\n",
       "      <th>top_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.082320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.081186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.081137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.079655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.076637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.073108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.072661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.071986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.067669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.065349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.060508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.059250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.056490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.055308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_sim_index  top_sim_score\n",
       "65            70.0       0.082320\n",
       "262          109.0       0.081186\n",
       "167           44.0       0.081137\n",
       "16            21.0       0.079655\n",
       "179          292.0       0.076637\n",
       "38           211.0       0.073108\n",
       "136          176.0       0.072661\n",
       "260          186.0       0.071986\n",
       "60             1.0       0.071899\n",
       "22           188.0       0.067669\n",
       "56            24.0       0.065349\n",
       "123          126.0       0.060508\n",
       "180          165.0       0.059250\n",
       "177           23.0       0.056490\n",
       "28           280.0       0.055308"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity between 207 and 206 is 0.20: \n",
      "\n",
      "selected doc:  I have been using this product for 5+ years. It was wonderful. About 1 year ago the company changed packaging and the product changed slightly. The bottle is taller now and something is missing from the serum. Doesn't work as well as it used to work. I will not be purchasing this item because of the change.\n",
      "\n",
      "similar doc:  I have been used this product for many years. But somehow the product I received this time is like fake one. It's very thin. I have to used double amount.\n",
      "\n",
      "Similarity between 10 and 15 is 0.16: \n",
      "\n",
      "selected doc:  A complete waste of time. Typographical errors, poor grammar, and a totally pathetic plot add up to absolutely nothing. I'm embarrassed for this author and very disappointed I actually paid for this book.\n",
      "\n",
      "similar doc:  It's glaringly obvious that all of the glowing reviews have been written by the same person, perhaps the author herself. They all have the same misspellings and poor sentence structure that is featured in the book. Who made Veronica Haddon think she is an author?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pick any doc id, e.g. 10, 207\n",
    "doc_id =207\n",
    "sim_doc_id, sim = find_similar_doc(data[\"review\"], doc_id)\n",
    "print(\"\\nSimilarity between {0} and {1} is {2:.2f}: \"\\\n",
    "          .format(doc_id, sim_doc_id, sim))\n",
    "print(\"\\nselected doc: \", data.loc[doc_id][\"review\"])\n",
    "print(\"\\nsimilar doc: \", data.loc[sim_doc_id][\"review\"])\n",
    "    \n",
    "    \n",
    "doc_id =10\n",
    "sim_doc_id, sim = find_similar_doc(data[\"review\"], doc_id)\n",
    "print(\"\\nSimilarity between {0} and {1} is {2:.2f}: \"\\\n",
    "          .format(doc_id, sim_doc_id, sim))\n",
    "print(\"\\nselected doc: \", data.loc[doc_id][\"review\"])\n",
    "print(\"\\nsimilar doc: \", data.loc[sim_doc_id][\"review\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(doc_id):\n",
    "    sim_doc_id, sim = find_similar_doc(data[\"review\"], doc_id)\n",
    "    print('\\n')\n",
    "    print(\"\\nSimilarity between {0} and {1} is {2:.2f}: \"\\\n",
    "          .format(doc_id, sim_doc_id, sim))\n",
    "    print(\"\\nselected doc: \", data.loc[doc_id][\"review\"])\n",
    "    print(\"\\nsimilar doc: \", data.loc[sim_doc_id][\"review\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
